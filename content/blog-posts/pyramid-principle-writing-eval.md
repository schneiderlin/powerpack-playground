```edn
:page/title "金字塔原理作为写作 Eval 的确定性评分器"
:page/description "探讨如何用金字塔原理作为半确定性评分器，替代传统 LLM as Judge 进行写作质量评估"
:page/date "2026-01-31"
:blog-post/tags [:AI :eval :writing]
:blog-post/author {:person/id :jan}
:page/body
```

## 背景

在 AI Eval System 中，核心原则是**优先使用确定性评分方法**，避免 LLM as Judge 的问题：递归倒退（谁来 judge judge？）、不确定性叠加、可调试性差。

写作任务也需要评分器。金字塔原理提供了一套明确的结构化标准，可以作为写作任务的半确定性评分器。

## 确定性谱系

金字塔原理测试位于确定性谱系的中间位置：

```
100% 确定性 ←────────────────────→ 20% 确定性

Type checker    金字塔原理测试          LLM as Judge
```

| 维度 | Type Checker | 金字塔原理测试 | LLM as Judge |
|------|--------------|----------------|--------------|
| 规则明确性 | 100%（唯一正确答案） | 80%（明确标准，需理解） | 20%（标准模糊） |
| 可复现性 | 100% | 高（> 90%） | 低（差异大） |
| 可调试性 | 报错位置精确 | 指出违反哪条原则 | "逻辑混乱"太抽象 |
| 成本 | 极低 | 中等（LLM执行规则） | 高（需详细prompt） |

本质是：金字塔原理测试更接近 **Design compliance / Linter**，而不是"让 LLM 主观评价文章质量"。

## 评分器设计

### Task

根据写作 prompt 生成文章后，自动评审文章质量。

### Dataset

所有写作内容（输入为 prompt，输出为文章）。

### Scorer：金字塔原理测试

- **结论先行测试**：开头 3 句内是否有明确结论
- **自上而下测试**：每层级是否有明确主题
- **归类分组测试**：同组论点是否属同一范畴
- **逻辑递进测试**：论点顺序是否合理
- **MECE 测试**：论点是否独立穷尽

### 运行流程

1. 遍历代码库中的所有文章
2. 运行每个 scorer 识别问题
3. 生成改进建议（不自动修改，只输出诊断报告）
4. 记录评审结果供人类 review

## LLM as Judge 的金字塔结构化

即使必须使用 LLM as Judge，也可以用金字塔原理提升确定性。

### 传统方式

```
文章 → LLM → "逻辑混乱"
```

问题：
- 结论黑盒，无法追溯
- 失败时无部分价值
- 难以调试

### 金字塔结构化

```
文章 → LLM → 
  结论：逻辑混乱
    ├─ 支撑点1：第3-4段应合并（都是数据相关）
    │   └─ 证据：第3段"数据质量"，第4段"数据量"
    ├─ 支撑点2：结论出现太晚（第7段）
    │   └─ 证据：第7段开头"总而言之..."
    └─ 支撑点3：第5段"但是"破坏结构
        └─ 证据：第5段引入"安全性"，前面无铺垫
```

### 价值

- **部分价值**：即使最终结论错了，子结论仍有用（如"点1对，但点2我不认同"）
- **可调试**：每个支撑点指向具体位置，可以逐一验证
- **确定性提高**：子结论更接近"Design compliance"而非纯主观
- **可追溯**：自下而上搭建结论，不是"拍脑袋"

## 写作 TDD

金字塔原理可以作为写作 TDD 的测试用例：

### TDD 流程

1. **先写测试**（金字塔原理检查清单）
2. **开始写作**
3. **迭代直到所有测试通过**

### 测试用例

- 文章开头 3 句话内是否有明确结论？
- 每个层级是否都有明确的主题？
- 同一组论点是否属于同一范畴？
- 论点之间的逻辑顺序是否合理？
- 论点之间是否有重叠或遗漏？

这完美体现了 AI Eval System 的核心原则：**确定性评分优于 LLM as Judge**。

## 适用场景

- **Sleep time compute**：人类睡觉时自动评审文章
- **回归测试**：文章修改后快速检查是否破坏结构
- **批量处理**：一次性评审多个文档

## 参考

关于 Sleep time compute 的详细讨论，见 [long-running-agents](./long-running-agents.md)。
